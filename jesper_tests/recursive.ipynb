{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [25, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMG_PATH = '../data/dss/scrolls/P123-Fg002-R-C01-R01-binarized.jpg'\n",
    "\n",
    "def pimg(im, **kwargs):\n",
    "    if im is None:\n",
    "        print('no image!')\n",
    "        return\n",
    "    try:\n",
    "        cim = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    except:\n",
    "        cim = im\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(cim, **kwargs)\n",
    "    plt.show()\n",
    "\n",
    "def write_cc(img, cc):\n",
    "    try:\n",
    "        cimg = cv.cvtColor(img, cv.COLOR_GRAY2RGB)\n",
    "    except:\n",
    "        cimg = img\n",
    "    cv.rectangle(cimg, (cc.x,cc.y), (cc.x+cc.w, cc.y+cc.h), (0,255,0), 2)\n",
    "    return cimg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from peakdetect import peakdetect\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ConnectedComponent:\n",
    "    \"\"\"A dataclass that contains all information for one connected component in an image.\n",
    "    \"\"\"\n",
    "    x: int\n",
    "    y: int\n",
    "    w: int\n",
    "    h: int\n",
    "    a: int\n",
    "    cx: float\n",
    "    cy: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LineSegment:\n",
    "    \"\"\"A dataclass that contains information necessary to put a line segment and its containing connected components\n",
    "    back into the originating image.\n",
    "    \"\"\"\n",
    "    top: ConnectedComponent\n",
    "    bot: ConnectedComponent\n",
    "    left: ConnectedComponent\n",
    "    right: ConnectedComponent\n",
    "    x_offset: int\n",
    "    y_offset: int\n",
    "    width: int\n",
    "    height: int\n",
    "    components: List[ConnectedComponent]\n",
    "\n",
    "\n",
    "def get_line_image_from_ccs(image: np.ndarray, ccs_line: List[ConnectedComponent]) -> Union[Tuple[np.ndarray, LineSegment], Tuple[None, None]]:\n",
    "    \"\"\"Given an image and a list of connected components, get a slice of the image that only contains the given\n",
    "    connected components.\n",
    "\n",
    "    :rtype: np.ndarray\n",
    "    :param image: The source image.\n",
    "    :param ccs_line: The connected components to slice with\n",
    "    :return: A slice of the source image containing only the given connected components\n",
    "    \"\"\"\n",
    "    # print(ccs_line)\n",
    "    if len(ccs_line) == 0:\n",
    "        return None, None\n",
    "    topmost_cc = ccs_line[np.argmin([cc.y for cc in ccs_line])]\n",
    "    bottommost_cc = ccs_line[np.argmax([cc.y + cc.h for cc in ccs_line])]\n",
    "    leftmost_cc = ccs_line[np.argmin([cc.x for cc in ccs_line])]\n",
    "    rightmost_cc = ccs_line[np.argmax([cc.x + cc.w for cc in ccs_line])]\n",
    "    height = bottommost_cc.y + bottommost_cc.h - topmost_cc.y\n",
    "    width = rightmost_cc.x + rightmost_cc.w - leftmost_cc.x\n",
    "    line_image = np.zeros((height, width), dtype=np.uint8)\n",
    "    x_offset = leftmost_cc.x\n",
    "    y_offset = topmost_cc.y\n",
    "    data = LineSegment(topmost_cc, bottommost_cc, leftmost_cc, rightmost_cc, x_offset, y_offset, width, height, ccs_line\n",
    "                       )\n",
    "    for cc in ccs_line:\n",
    "        y_l = cc.y - y_offset\n",
    "        x_l = cc.x - x_offset\n",
    "        line_image[y_l:y_l + cc.h, x_l:x_l + cc.w] = \\\n",
    "            image[cc.y:cc.y + cc.h, cc.x:cc.x + cc.w]\n",
    "    return line_image, data\n",
    "\n",
    "\n",
    "def get_ccs_per_line(ccs: List[ConnectedComponent], minima: List[List[int]], image_height: int) \\\n",
    "        -> List[List[ConnectedComponent]]:\n",
    "    \"\"\"Given a list of connected components and a list op minima (formatted as `peakdetect.peakdetect`), order the\n",
    "    connected components by the line it is contained within.\n",
    "\n",
    "    :param ccs: The connected components\n",
    "    :param minima: The list of minima (minima[x] = [location, value])\n",
    "    :param image_height: The height of the source image used to determine the last line height\n",
    "    :return: A list containing all connected components per line\n",
    "    \"\"\"\n",
    "    ccs_per_line = []\n",
    "    for i in range(len(minima) + 1):\n",
    "        curr_line = minima[i][0] if i < len(minima) else image_height\n",
    "        last_line = minima[i - 1][0] if i > 0 else 0\n",
    "        ccs_curr_line = [cc for cc in ccs if last_line <= cc.cy < curr_line]\n",
    "        ccs_per_line.append(ccs_curr_line)\n",
    "    return ccs_per_line\n",
    "\n",
    "\n",
    "def preprocessed(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return the source image, preprocessed (converted to greyscale and thresholded).\n",
    "\n",
    "    :param image: The source image\n",
    "    :return: The preprocessed source image.\n",
    "    \"\"\"\n",
    "    result = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    _, result = cv.threshold(result, 127, 255, cv.THRESH_BINARY_INV)\n",
    "    # result = skeletonize_pass(image)\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_cc(image: np.ndarray, cc: ConnectedComponent) -> np.ndarray:\n",
    "    \"\"\"Get a slice of an image that only contains the part that is contained within a connected component.\n",
    "\n",
    "    :param image: The source image\n",
    "    :param cc: The connected component\n",
    "    :return: The image slice\n",
    "    \"\"\"\n",
    "    return image[cc.y:cc.y + cc.h, cc.x:cc.x + cc.w]\n",
    "\n",
    "\n",
    "def get_ccs_from_image(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Get all connected components of an image.\n",
    "\n",
    "    :param image: The source image\n",
    "    :return: The list of connected components\n",
    "    \"\"\"\n",
    "    _, _, stats, centroids = cv.connectedComponentsWithStats(image)\n",
    "    return [\n",
    "        ConnectedComponent(*stat.tolist(), *centroids[i].tolist())\n",
    "        for i, stat in enumerate(stats)\n",
    "    ]\n",
    "\n",
    "\n",
    "def line_segment_image(input_image: np.ndarray, peak_lookahead: int = 40, cc_min_a: int = 500, cc_max_a: int = 1e5) \\\n",
    "        -> Tuple[List[np.ndarray], List[Dict[str, Any]]]:\n",
    "    \"\"\"Perform line segmentation on an image, using the reduction method.\n",
    "\n",
    "    :param input_image: The source image.\n",
    "    :param peak_lookahead: Lookahead used by the peak detection algorithm\n",
    "    :param cc_min_a: The minimum area of the connected components to use\n",
    "    :param cc_max_a: The maximum area of the connected components to use\n",
    "    :return: The line images and the metadata of the line segments\n",
    "    \"\"\"\n",
    "    image = preprocessed(input_image)\n",
    "    ccs = get_ccs_from_image(image)\n",
    "    ccs = [cc for cc in ccs if cc_min_a <= cc.a <= cc_max_a]\n",
    "    reduced = cv.reduce(image // 255, 1, cv.REDUCE_SUM, dtype=cv.CV_32S)\n",
    "    _, minima = peakdetect(reduced, lookahead=peak_lookahead)\n",
    "    ccs_per_line = get_ccs_per_line(ccs, minima, image.shape[1])\n",
    "    lines = [\n",
    "        get_line_image_from_ccs(image, ccs_line)\n",
    "        for ccs_line in ccs_per_line if ccs_line\n",
    "    ]\n",
    "    line_images = [line[0] for line in lines]\n",
    "    metadata = [asdict(line[1]) for line in lines]\n",
    "    return line_images, metadata\n",
    "\n",
    "\n",
    "class ProjectionSegmenter:\n",
    "    pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def skeletonize(image):\n",
    "    skeleton = np.zeros(image.shape, np.uint8)\n",
    "    se = cv.getStructuringElement(cv.MORPH_CROSS, (3,3))\n",
    "    while True:\n",
    "        opened = cv.morphologyEx(image, cv.MORPH_OPEN, se)\n",
    "        temp = cv.subtract(image, opened)\n",
    "        eroded = cv.erode(image, se)\n",
    "        skeleton = cv.bitwise_or(skeleton, temp)\n",
    "        image = eroded.copy()\n",
    "        if cv.countNonZero(image) == 0:\n",
    "            break\n",
    "\n",
    "    return skeleton\n",
    "\n",
    "def skeletonize_pass(image):\n",
    "    skeleton = np.zeros(image.shape, np.uint8)\n",
    "    se = cv.getStructuringElement(cv.MORPH_CROSS, (3,3))\n",
    "    opened = cv.morphologyEx(image, cv.MORPH_OPEN, se)\n",
    "    temp = cv.subtract(image, opened)\n",
    "    skeleton = cv.bitwise_or(skeleton, temp)\n",
    "    return skeleton\n",
    "\n",
    "def test():\n",
    "    img, d = line_segment_image(cv.imread(IMG_PATH), cc_min_a=1)\n",
    "    for im in img:\n",
    "        pimg(im, cmap='binary')\n",
    "\n",
    "# test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = cv.imread(IMG_PATH)\n",
    "pimg(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imutils import rotate_bound, rotate\n",
    "\n",
    "def crop(image):\n",
    "    coords = cv.findNonZero(image)\n",
    "    x,y,w,h = cv.boundingRect(coords)\n",
    "    return image[y:y+h, x:x+w], (x,y,w,h)\n",
    "\n",
    "def consecutive(array):\n",
    "    return np.split(array, np.where(np.diff(array) != 1)[0]+1)\n",
    "\n",
    "def reduce_optimally(image, axis=0):\n",
    "    best = 0\n",
    "    reductions = []\n",
    "    for angle in range(-20, 20, 2):\n",
    "        # print(best, angle)\n",
    "        # print(image.shape)\n",
    "        rotated = rotate(image, angle)\n",
    "        # print('shape:',rotated.shape)\n",
    "        # cropped, dims = crop(rotated)\n",
    "        # if len(cropped) == 0:\n",
    "        #     print(\"image contains only black pixels!\")\n",
    "        #     return None\n",
    "        reduced = cv.reduce(rotated // 255, axis, cv.REDUCE_SUM, dtype=cv.CV_32S).flatten()\n",
    "        _, minima = peakdetect(reduced, lookahead=60, delta=0)\n",
    "        # fig,(ax1, ax2) = plt.subplots(1, 2)\n",
    "        # ax1.imshow(cropped, cmap='binary')\n",
    "        # ax2.plot(reduced)\n",
    "        # plt.show()\n",
    "        # curr = len(consecutive(np.argwhere(reduced[30:-30]<=10).flatten()))\n",
    "        candidates = [minimum for minimum in minima if minimum[1] <= 30]\n",
    "        # print(f'a{angle}: {candidates}')\n",
    "        curr = len(candidates)\n",
    "        if curr > best:\n",
    "            best = curr\n",
    "            reductions = [(angle, candidates, (0,0,0,0))]\n",
    "        elif 0 < best == curr:\n",
    "            reductions.append((angle, candidates, (0,0,0,0)))\n",
    "\n",
    "    if not reductions:\n",
    "        print(\"could not find any peaks!\")\n",
    "        return None\n",
    "    print(reductions[len(reductions) // 2])\n",
    "    return reductions[len(reductions) // 2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://math.stackexchange.com/questions/1064832/rotate-a-line-by-a-given-angle-about-a-point\n",
    "https://www.desmos.com/calculator/jn7yhrvutv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rotated_line_eq(shape, angle, axis, val):\n",
    "    y0 = shape[0] // 2\n",
    "    x0 = shape[1] // 2\n",
    "    angle = angle * (np.pi / 180)\n",
    "    val *= -1\n",
    "    if axis == 0:\n",
    "        return \\\n",
    "            lambda x: x, \\\n",
    "            lambda y: int(round(-(((np.cos(angle) * (x - y0)) + y0 + val) / np.sin(angle)) + x0))\n",
    "    if axis == 1:\n",
    "        return \\\n",
    "            lambda x: int(round(-(((np.sin(angle) * (x - x0)) + y0 + val) / np.cos(angle)) + y0)), \\\n",
    "            lambda y: y\n",
    "\n",
    "def equations_from_reductions(image, angle, candidates, dimensions, axis):\n",
    "    # where_zeros = np.argwhere(reductions<=10).flatten()\n",
    "    # line_breaks = [int(np.mean(x)) for x in consecutive(where_zeros)]\n",
    "    # _, minima = peakdetect(candidates, lookahead=40, delta=10)\n",
    "    line_breaks, magnitudes = zip(*candidates)\n",
    "    for line_break in line_breaks:\n",
    "        # line_break += dimensions[axis] // 2\n",
    "        yield rotated_line_eq(image.shape, -angle, axis, line_break)\n",
    "\n",
    "def rot_from_red(image, angle, candidates, dimensions, axis):\n",
    "    # where_zeros = np.argwhere(reduced<=10).flatten()\n",
    "    # consecutive_zeros = np.split(where_zeros, np.where(np.diff(where_zeros) != 1)[0]+1)\n",
    "    # line_breaks = [int(np.mean(x)) for x in consecutive_zeros]\n",
    "    line_breaks, magnitudes = zip(*candidates)\n",
    "    img_rot = rotate(image, angle)\n",
    "    try:\n",
    "        img_rot = cv.cvtColor(img_rot, cv.COLOR_GRAY2RGB)\n",
    "    except:\n",
    "        pass\n",
    "        # print('couldnt change color')\n",
    "    for line_break  in line_breaks:\n",
    "        line_break += dimensions[axis] // 2\n",
    "        pt1 = [0,0]\n",
    "        pt2 = [img_rot.shape[axis], img_rot.shape[axis]]\n",
    "        pt1[axis] = line_break\n",
    "        pt2[axis] = line_break\n",
    "        cv.line(img_rot, tuple(pt1), tuple(pt2), (0,255,0))\n",
    "    return img_rot\n",
    "\n",
    "def test_rot(axis=1):\n",
    "    im = cv.imread(IMG_PATH)\n",
    "    # pimg(im)\n",
    "    im = preprocessed(im)\n",
    "    # pimg(im)\n",
    "    im, d = crop(im)\n",
    "    # pimb(im)\n",
    "    im = im[0:352, 615:1230]\n",
    "    im, d = crop(im)\n",
    "    print(im.shape)\n",
    "    reductions = reduce_optimally(im, axis=axis)\n",
    "    rim = rot_from_red(im, *reductions, axis=axis)\n",
    "    pimg(rim)\n",
    "    eqs = equations_from_reductions(im, *reductions, axis=axis)\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    for x,y in eqs:\n",
    "        print(x(0), y(0))\n",
    "        cv.line(im, (y(0), x(0)), (y(im.shape[1]), x(im.shape[1])), (0, 255, 0), 1)\n",
    "    pimg(im)\n",
    "\n",
    "test_rot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Rect:\n",
    "    x: int\n",
    "    y: int\n",
    "    w: int\n",
    "    h: int"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Image splitting methods\n",
    "def to_grid(image, n_rows, n_cols):\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    m = h // n_rows\n",
    "    n = w // n_cols\n",
    "    tiles = []\n",
    "    for r, y in enumerate(range(0, h, m)):\n",
    "        for c, x in enumerate(range(0, w, n)):\n",
    "            tile = image[y:y+m, x:x+n]\n",
    "            rect = Rect(x=x, y=y, w=n, h=m)\n",
    "            tiles.append((rect, tile))\n",
    "\n",
    "    return tiles\n",
    "\n",
    "def to_chunks(image, n_chunks):\n",
    "    w = image.shape[1]\n",
    "    chunk_w, remainder = divmod(w, n_chunks)\n",
    "    chunks = []\n",
    "    for i in range(n_chunks - remainder):\n",
    "        x = i * chunk_w\n",
    "        chunks.append(image[..., x:x+chunk_w])\n",
    "    for i in range(n_chunks - remainder, n_chunks):\n",
    "        x = i * chunk_w\n",
    "        chunks.append(image[..., x:x+chunk_w+1])\n",
    "    return chunks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test(axis=1):\n",
    "    im = cv.imread(IMG_PATH)\n",
    "    im = preprocessed(im)\n",
    "    ccs = get_ccs_from_image(im)\n",
    "    extreme_ccs = [cc for cc in ccs if cc.a < 500]\n",
    "    for cc in extreme_ccs:\n",
    "        im[cc.y:cc.y+cc.h, cc.x:cc.x+cc.w] = np.zeros((cc.h, cc.w))\n",
    "    im, d = crop(im)\n",
    "    pimg(im)\n",
    "    tiles = to_grid(im, 2, 2)\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    i=0\n",
    "    for (pos, tile) in tiles:\n",
    "        if cv.countNonZero(tile) < 5:\n",
    "            continue\n",
    "        reductions = reduce_optimally(tile, axis=axis)\n",
    "        tile, tile_dim = crop(tile)\n",
    "        tile = cv.cvtColor(tile, cv.COLOR_GRAY2RGB)\n",
    "        if reductions:\n",
    "            i+=1\n",
    "            path = f'/home/jsk/Study/2-4-hwr/Handwriting_Recognition/jesper_tests/out/{i}.jpg'\n",
    "            rotim = rot_from_red(tile, *reductions, axis=axis)\n",
    "            # print(f\"writing to {path}\")\n",
    "            cv.imwrite(path, rotim)\n",
    "            eqs = equations_from_reductions(tile, *reductions, axis=axis)\n",
    "            for x,y in eqs:\n",
    "                x_offset = pos.x + tile_dim[0]\n",
    "                y_offset = pos.y + tile_dim[1]\n",
    "                cv.line(tile, (y(0), x(0)), (y(tile.shape[1]), x(tile.shape[1])), (0, 255, 0), 1)\n",
    "                cv.line(im, (y(0)+x_offset, x(0)+y_offset), (y(tile.shape[1])+x_offset, x(tile.shape[1])+y_offset), (0, 255, 0), 1)\n",
    "            # print(r)\n",
    "            fig, (a1, a2) = plt.subplots(1, 2)\n",
    "            a1.imshow(rotim, cmap='binary')\n",
    "            a2.imshow(tile, cmap='binary')\n",
    "            plt.show()\n",
    "            # pimg(tile)\n",
    "    pimg(im)\n",
    "\n",
    "test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Things that were tried\n",
    "- Add new line when someone else is already bound to a previous line ending: Didn't help (only more shenanigans with lamed et consortes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def projection_profile(chunk, window_length=20):\n",
    "    reduced = cv.reduce(chunk // 255, 1, cv.REDUCE_SUM, dtype=cv.CV_32S).flatten()\n",
    "    kernel = np.ones(window_length) / window_length\n",
    "    return np.convolve(reduced, kernel, mode='same')\n",
    "\n",
    "\n",
    "def consecutive(array):\n",
    "    return np.split(array, np.where(np.diff(array) != 1)[0]+1)\n",
    "\n",
    "\n",
    "def valleys_from_profile(profile, lookahead, plot=False, *args, **kwargs):\n",
    "    peaks, _ = peakdetect(np.hstack((profile, [0]*lookahead)), lookahead=lookahead)\n",
    "    if len(peaks) == 0:\n",
    "        return []\n",
    "    peak_locs, _ = zip(*peaks)\n",
    "    # if 'second_pass' in args:\n",
    "    if plot:\n",
    "        plt.plot(profile)\n",
    "        for y in peak_locs:\n",
    "            plt.axvline(y)\n",
    "    valley_locs = []\n",
    "    for i, y in enumerate(peak_locs):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        y_lag = peak_locs[i-1]\n",
    "        if y_lag-y == 0:\n",
    "            continue\n",
    "        slice = profile[y_lag:y]\n",
    "        consec = consecutive(np.argwhere(slice==min(slice)).flatten())\n",
    "        longest_consec = consec[np.argmax(np.array(list(map(len, consec))))]\n",
    "        valley_locs.append(int(np.mean(longest_consec)) + y_lag)\n",
    "    if plot:\n",
    "        for valley in valley_locs:\n",
    "            plt.axvline(valley)\n",
    "        plt.show()\n",
    "    return valley_locs\n",
    "\n",
    "\n",
    "def valleys_from_profiles(profile, lookahead):\n",
    "    _, valleys = peakdetect(np.hstack((profile, [0]*lookahead)), lookahead=lookahead)\n",
    "    if len(valleys) == 0: return []\n",
    "    locs, _ = zip(*valleys)\n",
    "    return list(locs)\n",
    "\n",
    "\n",
    "def annotate_image_with_lines(im, chunks, lines):\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    for line in lines:\n",
    "        x = im.shape[1]\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            cv.line(im, (x,y), (x-w, y), (0, 255, 0), 2)\n",
    "            if i < len(line)-1:\n",
    "                prev_y = line[i-1]\n",
    "                cv.line(im, (x, y), (x,prev_y), (0, 255, 0), 2)\n",
    "            x -= w\n",
    "    return im\n",
    "\n",
    "\n",
    "def annotate_image_with_line_w(im, lines):\n",
    "    try:\n",
    "        im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    except:\n",
    "        pass\n",
    "    for line in lines:\n",
    "        x = im.shape[1]\n",
    "        for i, (y, w) in enumerate(line):\n",
    "            cv.line(im, (x, y), (x-w, y), (0, 255, 0), 2)\n",
    "            if i != 0:\n",
    "                prev_y = line[i-1][0]\n",
    "                cv.line(im, (x,y), (x, prev_y), (0, 255, 0), 2)\n",
    "            x -= w\n",
    "    return im\n",
    "\n",
    "def verbose(level):\n",
    "    def print_v(*args, **kwargs):\n",
    "        i = 5\n",
    "        if 'level' in kwargs:\n",
    "            i = kwargs['level']\n",
    "            del kwargs['level']\n",
    "        if i <= level:\n",
    "            print(*args, **kwargs)\n",
    "    return print_v\n",
    "\n",
    "def none(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "def traverse(im, n_splits=20, line_start_splits=10, start_lookahead=50, chunk_lookahead=40, expected_line_height=200, second_pass=False, log=none):\n",
    "    im, dims = crop(im)\n",
    "    # if second_pass:\n",
    "    #     print(\"Second pass!\")\n",
    "    #     pimg(im)\n",
    "    if cv.countNonZero(im) == 0:\n",
    "        print('Empty image!')\n",
    "        return [], dims\n",
    "    chunks = to_chunks(im, n_splits)\n",
    "\n",
    "    # Line starts\n",
    "    start = np.column_stack(tuple(chunks[-line_start_splits:]))\n",
    "    prof = projection_profile(start)\n",
    "    line_starts = valleys_from_profile(prof, lookahead=start_lookahead)\n",
    "    if len(line_starts) == 0:\n",
    "        return [], dims\n",
    "\n",
    "    lines = [[y] for y in line_starts]\n",
    "    valleys_per_chunk = [valleys_from_profile(projection_profile(chunk), reverse=False, lookahead=chunk_lookahead) \\\n",
    "                               for chunk in chunks]\n",
    "\n",
    "    # extra lines found in the middle\n",
    "    additional_lines = []\n",
    "\n",
    "    # Line traversal\n",
    "    for i in range(2, n_splits+1):\n",
    "        log(f'\\nChunk {i}')\n",
    "        curr_valleys = valleys_per_chunk[-i]\n",
    "        log(f'Valleys at {curr_valleys}')\n",
    "        line_ending_to_closest_valley = {}\n",
    "        line_endings = [line[-1] for line in lines]\n",
    "        log(f'Line endings at {line_endings}')\n",
    "        for valley in curr_valleys:\n",
    "            log(f'Valley {valley}')\n",
    "            distances = np.array([abs(valley - line_ending) for line_ending in line_endings])\n",
    "            log(f'\\tDistances: {distances}')\n",
    "            closest_line_ending_idx = np.argmin(distances)\n",
    "            closest_line_ending = line_endings[closest_line_ending_idx]\n",
    "            distance_to_closest_line_ending = distances[closest_line_ending_idx]\n",
    "            log(f'\\tClosest at {closest_line_ending_idx}: {closest_line_ending} w/ distance {distance_to_closest_line_ending}')\n",
    "            if distance_to_closest_line_ending > expected_line_height * .8:\n",
    "                log('\\tToo far!')\n",
    "                continue\n",
    "            if closest_line_ending in line_ending_to_closest_valley:\n",
    "                other, other_distance = line_ending_to_closest_valley[closest_line_ending]\n",
    "                log(f'\\tAlready used by {other} w/ dist {other_distance}')\n",
    "                if distance_to_closest_line_ending < other_distance:\n",
    "                    log(f'\\tIm closer! Throwing them out...')\n",
    "                    line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "                    # new_line = [closest_line_ending] * (i-2) + [other]\n",
    "                    # print(f\"new line at {valley}\")\n",
    "                    # lines.append(new_line)\n",
    "                else:\n",
    "                    # TODO: inline annotations oppikken\n",
    "                    log(f'\\tThey are closer, I guess I\\'m out...')\n",
    "                    # print(f'new line at {valley}')\n",
    "                    # new_line = [closest_line_ending] * (i-2) + [valley]\n",
    "                    # lines.append(new_line)\n",
    "\n",
    "            else:\n",
    "                log(f'\\tFirst! Assigning...')\n",
    "                line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "        log(line_ending_to_closest_valley)\n",
    "\n",
    "        for line in lines:\n",
    "            line_ending = line[-1]\n",
    "            log(f'looking for line from line ending {line_ending}')\n",
    "            next_y = line_ending_to_closest_valley[line_ending][0] if line_ending in line_ending_to_closest_valley else line_ending\n",
    "            log(f'next: {next_y}')\n",
    "            line.append(next_y)\n",
    "    # End for chunk in chunks\n",
    "\n",
    "    # Add line segment (chunk) size to every line segment\n",
    "    lines_full = []\n",
    "    for line in lines:\n",
    "        line_full = []\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            line_full += [(y, w)]\n",
    "        lines_full.append(line_full)\n",
    "\n",
    "    # Get heights of every line\n",
    "    line_heights = []\n",
    "    for i, line_start in enumerate(line_starts):\n",
    "        if i==0:\n",
    "            line_heights.append(line_start)\n",
    "        else:\n",
    "            line_heights.append(line_start - line_starts[i-1])\n",
    "    line_heights.append(im.shape[0] - line_starts[-1])\n",
    "    line_heights = np.array(line_heights)\n",
    "\n",
    "    # Add line starting at the top of im\n",
    "    line_starts.insert(0, 0)\n",
    "\n",
    "    imw = im.shape[1]\n",
    "    imh = im.shape[0]\n",
    "    mean = line_heights.mean()\n",
    "    std = line_heights.std()\n",
    "    for i, line_height in enumerate(line_heights):\n",
    "        # print(i, line_height)\n",
    "        if line_height > expected_line_height:\n",
    "            mess = 'nested' if second_pass else ''\n",
    "            log(f\"\\n{mess} second pass for line {i}\")\n",
    "            y_from = line_starts[i]\n",
    "            y_to = line_starts[i+1] if i < len(line_starts)-1 else im.shape[0]\n",
    "            nested_lines, (nx, ny, nw, nh) = traverse(im[y_from:y_to, ...], n_splits, line_start_splits, start_lookahead, chunk_lookahead, expected_line_height, second_pass=True, log=log)\n",
    "            y_offset = y_from + ny\n",
    "            nested_lines = [line for line in nested_lines if abs(line[0][0]+y_offset - y_from) > 30 and abs(line[0][0]+y_offset - y_to) > 30]\n",
    "            nested_lines = [[(line[0][0]+y_offset, imw-(nx+nw))] +\n",
    "                            [(y+y_offset, w) for y,w in line] +\n",
    "                            [(line[-1][0]+y_offset, nx)] \\\n",
    "                                for line in nested_lines]\n",
    "            log('Nested:', nested_lines)\n",
    "            for j, nested_line in enumerate(nested_lines):\n",
    "                lines_full.insert(i+j, nested_line)\n",
    "    # im = annotate_image_with_line_w(im, lines_full)\n",
    "    # pimg(im)\n",
    "    return lines_full, dims\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def test():\n",
    "    p = Path('../data/dss/scrolls')\n",
    "    files = p.glob('*binarized.jpg')\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        im = cv.imread(str(file))\n",
    "        im = preprocessed(im)\n",
    "        lines, (x,y,w,h) = traverse(im, log=verbose(1))\n",
    "        im = im[y:y+h, x:x+w]\n",
    "        ccs = get_ccs_from_image(im)\n",
    "        im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "        for cc in ccs:\n",
    "            cv.circle(im, (int(cc.cx), int(cc.cy)), 2, (255, 0, 0), 2)\n",
    "        im = annotate_image_with_line_w(im, lines)\n",
    "        pimg(im)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def image_between_lines(im, line1, line2, ccs, offset):\n",
    "    (ox,oy,ow,oh) = offset\n",
    "    def line_y_from_x(line, x):\n",
    "        curr_x = 0\n",
    "        for (y, w) in line:\n",
    "            if curr_x < x-ox <= curr_x + w:\n",
    "                return y+oy\n",
    "            curr_x += w\n",
    "        return line[-1][0]\n",
    "    ccs_line = []\n",
    "    for cc in ccs:\n",
    "        fbound = line_y_from_x(line1, cc.cx)\n",
    "        sbound = line_y_from_x(line2, cc.cx)\n",
    "        lbound = min(fbound, sbound)\n",
    "        ubound = max(fbound, sbound)\n",
    "        if lbound <= cc.cy <= ubound:\n",
    "            ccs_line.append(cc)\n",
    "    return get_line_image_from_ccs(im, ccs_line)[0]\n",
    "\n",
    "import os\n",
    "def pipeline(in_path, out_path, cc_min_a, cc_max_a, start_lookahead, chunk_lookahead, expected_line_height):\n",
    "    path = Path(in_path)\n",
    "    out = Path(out_path)\n",
    "    os.makedirs(out, exist_ok=True)\n",
    "    files = path.glob('*binarized.jpg')\n",
    "\n",
    "    def save(directory, id, oim):\n",
    "        fn = directory / f'line-{id}.jpg'\n",
    "        print(f'\\t=> {fn}')\n",
    "        if cv.countNonZero(oim) == 0: return False\n",
    "        cv.imwrite(str(fn), oim)\n",
    "        return True\n",
    "\n",
    "    for file in files:\n",
    "        print(str(file))\n",
    "        directory = out / file.name.split('.')[0]\n",
    "        os.makedirs(directory)\n",
    "        im = cv.imread(str(file))\n",
    "        im = preprocessed(im)\n",
    "        ccs = get_ccs_from_image(im)\n",
    "        ccs = [cc for cc in ccs if cc_min_a <= cc.a <= cc_max_a]\n",
    "        lines, offset = traverse(im,\n",
    "                                 start_lookahead=start_lookahead, chunk_lookahead=chunk_lookahead,\n",
    "                                 expected_line_height=expected_line_height, log=none)\n",
    "        lines = [[(0, im.shape[1])]] + lines + [[(im.shape[0], im.shape[1])]]\n",
    "        line_id = 0\n",
    "        for i, line in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            oim = image_between_lines(im, lines[i-1], line, ccs, offset)\n",
    "            if save(directory, line_id, oim):\n",
    "                line_id += 1\n",
    "\n",
    "pipeline(Path('../data/dss/scrolls'), Path('./out'), 500, 1e5, 50, 40, 200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p = Path('../data/dss/scrolls')\n",
    "files = p.glob('*binarized.jpg')\n",
    "for file in files:\n",
    "    print(file.name)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test(axis=1):\n",
    "    im = cv.imread(IMG_PATH)\n",
    "    im = preprocessed(im)\n",
    "    ccs = get_ccs_from_image(im)\n",
    "    extreme_ccs = [cc for cc in ccs if cc.a < 500]\n",
    "    for cc in extreme_ccs:\n",
    "        im[cc.y:cc.y+cc.h, cc.x:cc.x+cc.w] = np.zeros((cc.h, cc.w))\n",
    "    im, d = crop(im)\n",
    "    pimg(im)\n",
    "    tiles = to_grid(im, 2, 2)\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    i=0\n",
    "    for (pos, tile) in tiles:\n",
    "        if cv.countNonZero(tile) < 5:\n",
    "            continue\n",
    "        reductions = reduce_optimally(tile, axis=axis)\n",
    "        tile, tile_dim = crop(tile)\n",
    "        tile = cv.cvtColor(tile, cv.COLOR_GRAY2RGB)\n",
    "        if reductions:\n",
    "            i+=1\n",
    "            path = f'/home/jsk/Study/2-4-hwr/Handwriting_Recognition/jesper_tests/out/{i}.jpg'\n",
    "            rotim = rot_from_red(tile, *reductions, axis=axis)\n",
    "            # print(f\"writing to {path}\")\n",
    "            cv.imwrite(path, rotim)\n",
    "            eqs = equations_from_reductions(tile, *reductions, axis=axis)\n",
    "            for x,y in eqs:\n",
    "                x_offset = pos.x + tile_dim[0]\n",
    "                y_offset = pos.y + tile_dim[1]\n",
    "                cv.line(tile, (y(0), x(0)), (y(tile.shape[1]), x(tile.shape[1])), (0, 255, 0), 1)\n",
    "                cv.line(im, (y(0)+x_offset, x(0)+y_offset), (y(tile.shape[1])+x_offset, x(tile.shape[1])+y_offset), (0, 255, 0), 1)\n",
    "            # print(r)\n",
    "            fig, (a1, a2) = plt.subplots(1, 2)\n",
    "            a1.imshow(rotim, cmap='binary')\n",
    "            a2.imshow(tile, cmap='binary')\n",
    "            plt.show()\n",
    "            # pimg(tile)\n",
    "    pimg(im)\n",
    "\n",
    "test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def projection_profile(chunk, window_length=5):\n",
    "    reduced = cv.reduce(chunk // 255, 1, cv.REDUCE_SUM, dtype=cv.CV_32S).flatten()\n",
    "    kernel = np.ones(window_length) / window_length\n",
    "    return np.convolve(reduced, kernel, mode='same')\n",
    "\n",
    "\n",
    "def valleys_from_profile(profile, *args, **kwargs):\n",
    "    peaks, _ = peakdetect(profile, *args, **kwargs)\n",
    "    if len(peaks) == 0:\n",
    "        return []\n",
    "    peak_locs, _ = zip(*peaks)\n",
    "    # plt.plot(prof)\n",
    "    # for (x,y) in peaks:\n",
    "    #     plt.axvline(x)\n",
    "    # plt.show()\n",
    "    # start = cv.cvtColor(start, cv.COLOR_GRAY2RGB)\n",
    "    valley_locs = []\n",
    "    for i, y in enumerate(peak_locs):\n",
    "        if i==0:\n",
    "            continue\n",
    "        y_lag = peak_locs[i-1]\n",
    "        valley_locs.append(np.argmin(profile[y_lag:y]) + y_lag)\n",
    "        # valley = np.argmin(profile[y_lag:y]) + y_lag\n",
    "        # cv.line(start, (0, valley), (start.shape[1], valley), (0, 255, 0))\n",
    "    # plt.show()\n",
    "    # plt.imshow(start)\n",
    "    return valley_locs\n",
    "\n",
    "\n",
    "def annotate_image_with_lines(im, chunks, lines):\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    for line in lines:\n",
    "        x = im.shape[1]\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            cv.line(im, (x,y), (x-w,y), (0, 255, 0), 2)\n",
    "            if i < len(line)-1:\n",
    "                prev_y = line[i-1]\n",
    "                cv.line(im, (x,y), (x,prev_y), (0, 255, 0), 2)\n",
    "            x -= w\n",
    "    return im\n",
    "\n",
    "\n",
    "def none(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "def traverse(im, n_splits=20, line_start_splits=10, start_lookahead=70, chunk_lookahead=70, second_pass=False, log=none):\n",
    "    im, dims = crop(im)\n",
    "    if cv.countNonZero(im) == 0:\n",
    "        print('Empty image!')\n",
    "        return []\n",
    "    chunks = to_chunks(im, n_splits)\n",
    "\n",
    "    # Line starts\n",
    "    start = np.column_stack(tuple(chunks[-line_start_splits:]))\n",
    "    prof = projection_profile(start)\n",
    "    line_starts = valleys_from_profile(prof, lookahead=start_lookahead)\n",
    "    if len(line_starts) == 0:\n",
    "        print('Could not find any peaks!')\n",
    "        return []\n",
    "\n",
    "    lines = [[y] for y in line_starts]\n",
    "    valleys_per_chunk = [valleys_from_profile(projection_profile(chunk), lookahead=chunk_lookahead) \\\n",
    "                               for chunk in chunks]\n",
    "\n",
    "    # Line traversal\n",
    "    for i in range(2, n_splits+1):\n",
    "        log(f'\\nChunk {i}')\n",
    "        curr_valleys = valleys_per_chunk[-i]\n",
    "        log(f'Valleys at {curr_valleys}')\n",
    "        line_ending_to_closest_valley = {}\n",
    "        line_endings = [line[-1] for line in lines]\n",
    "        log(f'Line endings at {line_endings}')\n",
    "        for valley in curr_valleys:\n",
    "            log(f'Valley {valley}')\n",
    "            distances = np.array([abs(valley - line_ending) for line_ending in line_endings])\n",
    "            log(f'\\tDistances: {distances}')\n",
    "            closest_line_ending_idx = np.argmin(distances)\n",
    "            closest_line_ending = line_endings[closest_line_ending_idx]\n",
    "            distance_to_closest_line_ending = distances[closest_line_ending_idx]\n",
    "            log(f'\\tClosest at {closest_line_ending_idx}: {closest_line_ending} w/ distance {distance_to_closest_line_ending}')\n",
    "            if distance_to_closest_line_ending > 60:\n",
    "                log('\\tToo far away!')\n",
    "                continue\n",
    "            if closest_line_ending in line_ending_to_closest_valley:\n",
    "                other, other_distance = line_ending_to_closest_valley[closest_line_ending]\n",
    "                log(f'\\tAlready used by {other} w/ dist {other_distance}')\n",
    "                if distance_to_closest_line_ending < other_distance:\n",
    "                    log(f'\\tIm closer! Throwing them out...')\n",
    "                    line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "                else:\n",
    "                    # TODO: inline annotations oppikken\n",
    "                    log(f'\\tThey are closer, carefully dying...')\n",
    "            else:\n",
    "                log(f'\\tFirst! Assigning...')\n",
    "                line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "        log(line_ending_to_closest_valley)\n",
    "\n",
    "        for line in lines:\n",
    "            line_ending = line[-1]\n",
    "            log(f'looking for line from line ending {line_ending}')\n",
    "            next_y = line_ending_to_closest_valley[line_ending][0] if line_ending in line_ending_to_closest_valley else line_ending\n",
    "            log(f'next: {next_y}')\n",
    "            line.append(next_y)\n",
    "    # End for chunk in chunks\n",
    "\n",
    "    # Get heights of every line\n",
    "    line_heights = []\n",
    "    for i, line_start in enumerate(line_starts):\n",
    "        if i==0:\n",
    "            line_heights.append(line_start)\n",
    "        else:\n",
    "            line_heights.append(line_start - line_starts[i-1])\n",
    "    line_heights.append(im.shape[0] - line_starts[-1])\n",
    "    line_heights = np.array(line_heights)\n",
    "\n",
    "    mean = line_heights.mean()\n",
    "    std = line_heights.std()\n",
    "    print(line_heights)\n",
    "    for i, line_height in enumerate(line_heights):\n",
    "        if line_height - mean > std:\n",
    "            print(f\"Second pass for line {i}\")\n",
    "            y_from = line_starts[i]\n",
    "            y_to = line_starts[i+1] if i < len(line_starts) else im.shape[0]\n",
    "            nested_lines, (nx, ny, nw, nh) = traverse(im[y_from:y_to, ...], n_splits, line_start_splits, start_lookahead, chunk_lookahead, second_pass=True, log=log)\n",
    "            nested_lines = []\n",
    "            for j, nested_line in enumerate(nested_lines):\n",
    "                lines.insert(i+j, nested_line)\n",
    "            # do something\n",
    "\n",
    "    lines_full = []\n",
    "    for line in lines:\n",
    "        line_full = []\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            line_full += [(y, w)]\n",
    "        lines_full.append(line_full)\n",
    "\n",
    "    return lines_full, dims\n",
    "    #\n",
    "    # im = annotate_image_with_lines(im, chunks, lines)\n",
    "    # pimg(im)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def test():\n",
    "    p = Path('../data/dss/scrolls')\n",
    "    files = p.glob('*binarized.jpg')\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        im = cv.imread(str(file))\n",
    "        im = preprocessed(im)\n",
    "        traverse(im)\n",
    "\n",
    "test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test(axis=1):\n",
    "    im = cv.imread(IMG_PATH)\n",
    "    im = preprocessed(im)\n",
    "    ccs = get_ccs_from_image(im)\n",
    "    extreme_ccs = [cc for cc in ccs if cc.a < 500]\n",
    "    for cc in extreme_ccs:\n",
    "        im[cc.y:cc.y+cc.h, cc.x:cc.x+cc.w] = np.zeros((cc.h, cc.w))\n",
    "    im, d = crop(im)\n",
    "    pimg(im)\n",
    "    tiles = to_grid(im, 2, 2)\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    i=0\n",
    "    for (pos, tile) in tiles:\n",
    "        if cv.countNonZero(tile) < 5:\n",
    "            continue\n",
    "        reductions = reduce_optimally(tile, axis=axis)\n",
    "        tile, tile_dim = crop(tile)\n",
    "        tile = cv.cvtColor(tile, cv.COLOR_GRAY2RGB)\n",
    "        if reductions:\n",
    "            i+=1\n",
    "            path = f'/home/jsk/Study/2-4-hwr/Handwriting_Recognition/jesper_tests/out/{i}.jpg'\n",
    "            rotim = rot_from_red(tile, *reductions, axis=axis)\n",
    "            # print(f\"writing to {path}\")\n",
    "            cv.imwrite(path, rotim)\n",
    "            eqs = equations_from_reductions(tile, *reductions, axis=axis)\n",
    "            for x,y in eqs:\n",
    "                x_offset = pos.x + tile_dim[0]\n",
    "                y_offset = pos.y + tile_dim[1]\n",
    "                cv.line(tile, (y(0), x(0)), (y(tile.shape[1]), x(tile.shape[1])), (0, 255, 0), 1)\n",
    "                cv.line(im, (y(0)+x_offset, x(0)+y_offset), (y(tile.shape[1])+x_offset, x(tile.shape[1])+y_offset), (0, 255, 0), 1)\n",
    "            # print(r)\n",
    "            fig, (a1, a2) = plt.subplots(1, 2)\n",
    "            a1.imshow(rotim, cmap='binary')\n",
    "            a2.imshow(tile, cmap='binary')\n",
    "            plt.show()\n",
    "            # pimg(tile)\n",
    "    pimg(im)\n",
    "\n",
    "#test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def projection_profile(chunk, window_length=5):\n",
    "    reduced = cv.reduce(chunk // 255, 1, cv.REDUCE_SUM, dtype=cv.CV_32S).flatten()\n",
    "    kernel = np.ones(window_length) / window_length\n",
    "    return np.convolve(reduced, kernel, mode='same')\n",
    "\n",
    "\n",
    "def valleys_from_profile(profile, *args, **kwargs):\n",
    "    peaks, _ = peakdetect(profile, *args, **kwargs)\n",
    "    if len(peaks) == 0:\n",
    "        return []\n",
    "    peak_locs, _ = zip(*peaks)\n",
    "    # plt.plot(prof)\n",
    "    # for (x,y) in peaks:\n",
    "    #     plt.axvline(x)\n",
    "    # plt.show()\n",
    "    # start = cv.cvtColor(start, cv.COLOR_GRAY2RGB)\n",
    "    valley_locs = []\n",
    "    for i, y in enumerate(peak_locs):\n",
    "        if i==0:\n",
    "            continue\n",
    "        y_lag = peak_locs[i-1]\n",
    "        valley_locs.append(np.argmin(profile[y_lag:y]) + y_lag)\n",
    "        # valley = np.argmin(profile[y_lag:y]) + y_lag\n",
    "        # cv.line(start, (0, valley), (start.shape[1], valley), (0, 255, 0))\n",
    "    # plt.show()\n",
    "    # plt.imshow(start)\n",
    "    return valley_locs\n",
    "\n",
    "\n",
    "def annotate_image_with_lines(im, chunks, lines):\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    for line in lines:\n",
    "        x = im.shape[1]\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            cv.line(im, (x,y), (x-w,y), (0, 255, 0), 2)\n",
    "            if i < len(line)-1:\n",
    "                prev_y = line[i-1]\n",
    "                cv.line(im, (x,y), (x,prev_y), (0, 255, 0), 2)\n",
    "            x -= w\n",
    "    return im\n",
    "\n",
    "\n",
    "def none(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "def traverse(im, n_splits=20, line_start_splits=10, start_lookahead=70, chunk_lookahead=70, second_pass=False, log=none):\n",
    "    im, dims = crop(im)\n",
    "    if cv.countNonZero(im) == 0:\n",
    "        print('Empty image!')\n",
    "        return []\n",
    "    chunks = to_chunks(im, n_splits)\n",
    "\n",
    "    # Line starts\n",
    "    start = np.column_stack(tuple(chunks[-line_start_splits:]))\n",
    "    prof = projection_profile(start)\n",
    "    line_starts = valleys_from_profile(prof, lookahead=start_lookahead)\n",
    "    if len(line_starts) == 0:\n",
    "        print('Could not find any peaks!')\n",
    "        return []\n",
    "\n",
    "    lines = [[y] for y in line_starts]\n",
    "    valleys_per_chunk = [valleys_from_profile(projection_profile(chunk), lookahead=chunk_lookahead) \\\n",
    "                               for chunk in chunks]\n",
    "\n",
    "    # Line traversal\n",
    "    for i in range(2, n_splits+1):\n",
    "        log(f'\\nChunk {i}')\n",
    "        curr_valleys = valleys_per_chunk[-i]\n",
    "        log(f'Valleys at {curr_valleys}')\n",
    "        line_ending_to_closest_valley = {}\n",
    "        line_endings = [line[-1] for line in lines]\n",
    "        log(f'Line endings at {line_endings}')\n",
    "        for valley in curr_valleys:\n",
    "            log(f'Valley {valley}')\n",
    "            distances = np.array([abs(valley - line_ending) for line_ending in line_endings])\n",
    "            log(f'\\tDistances: {distances}')\n",
    "            closest_line_ending_idx = np.argmin(distances)\n",
    "            closest_line_ending = line_endings[closest_line_ending_idx]\n",
    "            distance_to_closest_line_ending = distances[closest_line_ending_idx]\n",
    "            log(f'\\tClosest at {closest_line_ending_idx}: {closest_line_ending} w/ distance {distance_to_closest_line_ending}')\n",
    "            if distance_to_closest_line_ending > 60:\n",
    "                log('\\tToo far away!')\n",
    "                continue\n",
    "            if closest_line_ending in line_ending_to_closest_valley:\n",
    "                other, other_distance = line_ending_to_closest_valley[closest_line_ending]\n",
    "                log(f'\\tAlready used by {other} w/ dist {other_distance}')\n",
    "                if distance_to_closest_line_ending < other_distance:\n",
    "                    log(f'\\tIm closer! Throwing them out...')\n",
    "                    line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "                else:\n",
    "                    # TODO: inline annotations oppikken\n",
    "                    log(f'\\tThey are closer, carefully dying...')\n",
    "            else:\n",
    "                log(f'\\tFirst! Assigning...')\n",
    "                line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "        log(line_ending_to_closest_valley)\n",
    "\n",
    "        for line in lines:\n",
    "            line_ending = line[-1]\n",
    "            log(f'looking for line from line ending {line_ending}')\n",
    "            next_y = line_ending_to_closest_valley[line_ending][0] if line_ending in line_ending_to_closest_valley else line_ending\n",
    "            log(f'next: {next_y}')\n",
    "            line.append(next_y)\n",
    "    # End for chunk in chunks\n",
    "\n",
    "    # Get heights of every line\n",
    "    line_heights = []\n",
    "    for i, line_start in enumerate(line_starts):\n",
    "        if i==0:\n",
    "            line_heights.append(line_start)\n",
    "        else:\n",
    "            line_heights.append(line_start - line_starts[i-1])\n",
    "    line_heights.append(im.shape[0] - line_starts[-1])\n",
    "    line_heights = np.array(line_heights)\n",
    "\n",
    "    mean = line_heights.mean()\n",
    "    std = line_heights.std()\n",
    "    print(line_heights)\n",
    "    for i, line_height in enumerate(line_heights):\n",
    "        if line_height - mean > std:\n",
    "            print(f\"Second pass for line {i}\")\n",
    "            y_from = line_starts[i]\n",
    "            y_to = line_starts[i+1] if i < len(line_starts) else im.shape[0]\n",
    "            nested_lines, (nx, ny, nw, nh) = traverse(im[y_from:y_to, ...], n_splits, line_start_splits, start_lookahead, chunk_lookahead, second_pass=True, log=log)\n",
    "            nested_lines = []\n",
    "            for j, nested_line in enumerate(nested_lines):\n",
    "                lines.insert(i+j, nested_line)\n",
    "            # do something\n",
    "\n",
    "    lines_full = []\n",
    "    for line in lines:\n",
    "        line_full = []\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            line_full += [(y, w)]\n",
    "        lines_full.append(line_full)\n",
    "\n",
    "    return lines_full, dims\n",
    "    #\n",
    "    # im = annotate_image_with_lines(im, chunks, lines)\n",
    "    # pimg(im)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def test():\n",
    "    p = Path('../data/dss/scrolls')\n",
    "    files = p.glob('*binarized.jpg')\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        im = cv.imread(str(file))\n",
    "        im = preprocessed(im)\n",
    "        traverse(im)\n",
    "\n",
    "#test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test(axis=1):\n",
    "    im = cv.imread(IMG_PATH)\n",
    "    im = preprocessed(im)\n",
    "    ccs = get_ccs_from_image(im)\n",
    "    extreme_ccs = [cc for cc in ccs if cc.a < 500]\n",
    "    for cc in extreme_ccs:\n",
    "        im[cc.y:cc.y+cc.h, cc.x:cc.x+cc.w] = np.zeros((cc.h, cc.w))\n",
    "    im, d = crop(im)\n",
    "    pimg(im)\n",
    "    tiles = to_grid(im, 2, 2)\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    i=0\n",
    "    for (pos, tile) in tiles:\n",
    "        if cv.countNonZero(tile) < 5:\n",
    "            continue\n",
    "        reductions = reduce_optimally(tile, axis=axis)\n",
    "        tile, tile_dim = crop(tile)\n",
    "        tile = cv.cvtColor(tile, cv.COLOR_GRAY2RGB)\n",
    "        if reductions:\n",
    "            i+=1\n",
    "            path = f'/home/jsk/Study/2-4-hwr/Handwriting_Recognition/jesper_tests/out/{i}.jpg'\n",
    "            rotim = rot_from_red(tile, *reductions, axis=axis)\n",
    "            # print(f\"writing to {path}\")\n",
    "            cv.imwrite(path, rotim)\n",
    "            eqs = equations_from_reductions(tile, *reductions, axis=axis)\n",
    "            for x,y in eqs:\n",
    "                x_offset = pos.x + tile_dim[0]\n",
    "                y_offset = pos.y + tile_dim[1]\n",
    "                cv.line(tile, (y(0), x(0)), (y(tile.shape[1]), x(tile.shape[1])), (0, 255, 0), 1)\n",
    "                cv.line(im, (y(0)+x_offset, x(0)+y_offset), (y(tile.shape[1])+x_offset, x(tile.shape[1])+y_offset), (0, 255, 0), 1)\n",
    "            # print(r)\n",
    "            fig, (a1, a2) = plt.subplots(1, 2)\n",
    "            a1.imshow(rotim, cmap='binary')\n",
    "            a2.imshow(tile, cmap='binary')\n",
    "            plt.show()\n",
    "            # pimg(tile)\n",
    "    pimg(im)\n",
    "\n",
    "#test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def projection_profile(chunk, window_length=5):\n",
    "    reduced = cv.reduce(chunk // 255, 1, cv.REDUCE_SUM, dtype=cv.CV_32S).flatten()\n",
    "    kernel = np.ones(window_length) / window_length\n",
    "    return np.convolve(reduced, kernel, mode='same')\n",
    "\n",
    "\n",
    "def valleys_from_profile(profile, *args, **kwargs):\n",
    "    peaks, _ = peakdetect(profile, *args, **kwargs)\n",
    "    if len(peaks) == 0:\n",
    "        return []\n",
    "    peak_locs, _ = zip(*peaks)\n",
    "    # plt.plot(prof)\n",
    "    # for (x,y) in peaks:\n",
    "    #     plt.axvline(x)\n",
    "    # plt.show()\n",
    "    # start = cv.cvtColor(start, cv.COLOR_GRAY2RGB)\n",
    "    valley_locs = []\n",
    "    for i, y in enumerate(peak_locs):\n",
    "        if i==0:\n",
    "            continue\n",
    "        y_lag = peak_locs[i-1]\n",
    "        valley_locs.append(np.argmin(profile[y_lag:y]) + y_lag)\n",
    "        # valley = np.argmin(profile[y_lag:y]) + y_lag\n",
    "        # cv.line(start, (0, valley), (start.shape[1], valley), (0, 255, 0))\n",
    "    # plt.show()\n",
    "    # plt.imshow(start)\n",
    "    return valley_locs\n",
    "\n",
    "\n",
    "def annotate_image_with_lines(im, chunks, lines):\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    for line in lines:\n",
    "        x = im.shape[1]\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            cv.line(im, (x,y), (x-w,y), (0, 255, 0), 2)\n",
    "            if i < len(line)-1:\n",
    "                prev_y = line[i-1]\n",
    "                cv.line(im, (x,y), (x,prev_y), (0, 255, 0), 2)\n",
    "            x -= w\n",
    "    return im\n",
    "\n",
    "\n",
    "def none(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "def traverse(im, n_splits=20, line_start_splits=10, start_lookahead=70, chunk_lookahead=70, second_pass=False, log=none):\n",
    "    im, dims = crop(im)\n",
    "    if cv.countNonZero(im) == 0:\n",
    "        print('Empty image!')\n",
    "        return []\n",
    "    chunks = to_chunks(im, n_splits)\n",
    "\n",
    "    # Line starts\n",
    "    start = np.column_stack(tuple(chunks[-line_start_splits:]))\n",
    "    prof = projection_profile(start)\n",
    "    line_starts = valleys_from_profile(prof, lookahead=start_lookahead)\n",
    "    if len(line_starts) == 0:\n",
    "        print('Could not find any peaks!')\n",
    "        return []\n",
    "\n",
    "    lines = [[y] for y in line_starts]\n",
    "    valleys_per_chunk = [valleys_from_profile(projection_profile(chunk), lookahead=chunk_lookahead) \\\n",
    "                               for chunk in chunks]\n",
    "\n",
    "    # Line traversal\n",
    "    for i in range(2, n_splits+1):\n",
    "        log(f'\\nChunk {i}')\n",
    "        curr_valleys = valleys_per_chunk[-i]\n",
    "        log(f'Valleys at {curr_valleys}')\n",
    "        line_ending_to_closest_valley = {}\n",
    "        line_endings = [line[-1] for line in lines]\n",
    "        log(f'Line endings at {line_endings}')\n",
    "        for valley in curr_valleys:\n",
    "            log(f'Valley {valley}')\n",
    "            distances = np.array([abs(valley - line_ending) for line_ending in line_endings])\n",
    "            log(f'\\tDistances: {distances}')\n",
    "            closest_line_ending_idx = np.argmin(distances)\n",
    "            closest_line_ending = line_endings[closest_line_ending_idx]\n",
    "            distance_to_closest_line_ending = distances[closest_line_ending_idx]\n",
    "            log(f'\\tClosest at {closest_line_ending_idx}: {closest_line_ending} w/ distance {distance_to_closest_line_ending}')\n",
    "            if distance_to_closest_line_ending > 60:\n",
    "                log('\\tToo far away!')\n",
    "                continue\n",
    "            if closest_line_ending in line_ending_to_closest_valley:\n",
    "                other, other_distance = line_ending_to_closest_valley[closest_line_ending]\n",
    "                log(f'\\tAlready used by {other} w/ dist {other_distance}')\n",
    "                if distance_to_closest_line_ending < other_distance:\n",
    "                    log(f'\\tIm closer! Throwing them out...')\n",
    "                    line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "                else:\n",
    "                    # TODO: inline annotations oppikken\n",
    "                    log(f'\\tThey are closer, carefully dying...')\n",
    "            else:\n",
    "                log(f'\\tFirst! Assigning...')\n",
    "                line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "        log(line_ending_to_closest_valley)\n",
    "\n",
    "        for line in lines:\n",
    "            line_ending = line[-1]\n",
    "            log(f'looking for line from line ending {line_ending}')\n",
    "            next_y = line_ending_to_closest_valley[line_ending][0] if line_ending in line_ending_to_closest_valley else line_ending\n",
    "            log(f'next: {next_y}')\n",
    "            line.append(next_y)\n",
    "    # End for chunk in chunks\n",
    "\n",
    "    # Get heights of every line\n",
    "    line_heights = []\n",
    "    for i, line_start in enumerate(line_starts):\n",
    "        if i==0:\n",
    "            line_heights.append(line_start)\n",
    "        else:\n",
    "            line_heights.append(line_start - line_starts[i-1])\n",
    "    line_heights.append(im.shape[0] - line_starts[-1])\n",
    "    line_heights = np.array(line_heights)\n",
    "\n",
    "    mean = line_heights.mean()\n",
    "    std = line_heights.std()\n",
    "    print(line_heights)\n",
    "    for i, line_height in enumerate(line_heights):\n",
    "        if line_height - mean > std:\n",
    "            print(f\"Second pass for line {i}\")\n",
    "            y_from = line_starts[i]\n",
    "            y_to = line_starts[i+1] if i < len(line_starts) else im.shape[0]\n",
    "            nested_lines, (nx, ny, nw, nh) = traverse(im[y_from:y_to, ...], n_splits, line_start_splits, start_lookahead, chunk_lookahead, second_pass=True, log=log)\n",
    "            nested_lines = []\n",
    "            for j, nested_line in enumerate(nested_lines):\n",
    "                lines.insert(i+j, nested_line)\n",
    "            # do something\n",
    "\n",
    "    lines_full = []\n",
    "    for line in lines:\n",
    "        line_full = []\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            line_full += [(y, w)]\n",
    "        lines_full.append(line_full)\n",
    "\n",
    "    return lines_full, dims\n",
    "    #\n",
    "    # im = annotate_image_with_lines(im, chunks, lines)\n",
    "    # pimg(im)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def test():\n",
    "    p = Path('../data/dss/scrolls')\n",
    "    files = p.glob('*binarized.jpg')\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        im = cv.imread(str(file))\n",
    "        im = preprocessed(im)\n",
    "        traverse(im)\n",
    "\n",
    "#test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test(axis=1):\n",
    "    im = cv.imread(IMG_PATH)\n",
    "    im = preprocessed(im)\n",
    "    ccs = get_ccs_from_image(im)\n",
    "    extreme_ccs = [cc for cc in ccs if cc.a < 500]\n",
    "    for cc in extreme_ccs:\n",
    "        im[cc.y:cc.y+cc.h, cc.x:cc.x+cc.w] = np.zeros((cc.h, cc.w))\n",
    "    im, d = crop(im)\n",
    "    pimg(im)\n",
    "    tiles = to_grid(im, 2, 2)\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    i=0\n",
    "    for (pos, tile) in tiles:\n",
    "        if cv.countNonZero(tile) < 5:\n",
    "            continue\n",
    "        reductions = reduce_optimally(tile, axis=axis)\n",
    "        tile, tile_dim = crop(tile)\n",
    "        tile = cv.cvtColor(tile, cv.COLOR_GRAY2RGB)\n",
    "        if reductions:\n",
    "            i+=1\n",
    "            path = f'/home/jsk/Study/2-4-hwr/Handwriting_Recognition/jesper_tests/out/{i}.jpg'\n",
    "            rotim = rot_from_red(tile, *reductions, axis=axis)\n",
    "            # print(f\"writing to {path}\")\n",
    "            cv.imwrite(path, rotim)\n",
    "            eqs = equations_from_reductions(tile, *reductions, axis=axis)\n",
    "            for x,y in eqs:\n",
    "                x_offset = pos.x + tile_dim[0]\n",
    "                y_offset = pos.y + tile_dim[1]\n",
    "                cv.line(tile, (y(0), x(0)), (y(tile.shape[1]), x(tile.shape[1])), (0, 255, 0), 1)\n",
    "                cv.line(im, (y(0)+x_offset, x(0)+y_offset), (y(tile.shape[1])+x_offset, x(tile.shape[1])+y_offset), (0, 255, 0), 1)\n",
    "            # print(r)\n",
    "            fig, (a1, a2) = plt.subplots(1, 2)\n",
    "            a1.imshow(rotim, cmap='binary')\n",
    "            a2.imshow(tile, cmap='binary')\n",
    "            plt.show()\n",
    "            # pimg(tile)\n",
    "    pimg(im)\n",
    "\n",
    "#test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def projection_profile(chunk, window_length=5):\n",
    "    reduced = cv.reduce(chunk // 255, 1, cv.REDUCE_SUM, dtype=cv.CV_32S).flatten()\n",
    "    kernel = np.ones(window_length) / window_length\n",
    "    return np.convolve(reduced, kernel, mode='same')\n",
    "\n",
    "\n",
    "def valleys_from_profile(profile, *args, **kwargs):\n",
    "    peaks, _ = peakdetect(profile, *args, **kwargs)\n",
    "    if len(peaks) == 0:\n",
    "        return []\n",
    "    peak_locs, _ = zip(*peaks)\n",
    "    # plt.plot(prof)\n",
    "    # for (x,y) in peaks:\n",
    "    #     plt.axvline(x)\n",
    "    # plt.show()\n",
    "    # start = cv.cvtColor(start, cv.COLOR_GRAY2RGB)\n",
    "    valley_locs = []\n",
    "    for i, y in enumerate(peak_locs):\n",
    "        if i==0:\n",
    "            continue\n",
    "        y_lag = peak_locs[i-1]\n",
    "        valley_locs.append(np.argmin(profile[y_lag:y]) + y_lag)\n",
    "        # valley = np.argmin(profile[y_lag:y]) + y_lag\n",
    "        # cv.line(start, (0, valley), (start.shape[1], valley), (0, 255, 0))\n",
    "    # plt.show()\n",
    "    # plt.imshow(start)\n",
    "    return valley_locs\n",
    "\n",
    "\n",
    "def annotate_image_with_lines(im, chunks, lines):\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    for line in lines:\n",
    "        x = im.shape[1]\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            cv.line(im, (x,y), (x-w,y), (0, 255, 0), 2)\n",
    "            if i < len(line)-1:\n",
    "                prev_y = line[i-1]\n",
    "                cv.line(im, (x,y), (x,prev_y), (0, 255, 0), 2)\n",
    "            x -= w\n",
    "    return im\n",
    "\n",
    "\n",
    "def none(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "def traverse(im, n_splits=20, line_start_splits=10, start_lookahead=70, chunk_lookahead=70, second_pass=False, log=none):\n",
    "    im, dims = crop(im)\n",
    "    if cv.countNonZero(im) == 0:\n",
    "        print('Empty image!')\n",
    "        return []\n",
    "    chunks = to_chunks(im, n_splits)\n",
    "\n",
    "    # Line starts\n",
    "    start = np.column_stack(tuple(chunks[-line_start_splits:]))\n",
    "    prof = projection_profile(start)\n",
    "    line_starts = valleys_from_profile(prof, lookahead=start_lookahead)\n",
    "    if len(line_starts) == 0:\n",
    "        print('Could not find any peaks!')\n",
    "        return []\n",
    "\n",
    "    lines = [[y] for y in line_starts]\n",
    "    valleys_per_chunk = [valleys_from_profile(projection_profile(chunk), lookahead=chunk_lookahead) \\\n",
    "                               for chunk in chunks]\n",
    "\n",
    "    # Line traversal\n",
    "    for i in range(2, n_splits+1):\n",
    "        log(f'\\nChunk {i}')\n",
    "        curr_valleys = valleys_per_chunk[-i]\n",
    "        log(f'Valleys at {curr_valleys}')\n",
    "        line_ending_to_closest_valley = {}\n",
    "        line_endings = [line[-1] for line in lines]\n",
    "        log(f'Line endings at {line_endings}')\n",
    "        for valley in curr_valleys:\n",
    "            log(f'Valley {valley}')\n",
    "            distances = np.array([abs(valley - line_ending) for line_ending in line_endings])\n",
    "            log(f'\\tDistances: {distances}')\n",
    "            closest_line_ending_idx = np.argmin(distances)\n",
    "            closest_line_ending = line_endings[closest_line_ending_idx]\n",
    "            distance_to_closest_line_ending = distances[closest_line_ending_idx]\n",
    "            log(f'\\tClosest at {closest_line_ending_idx}: {closest_line_ending} w/ distance {distance_to_closest_line_ending}')\n",
    "            if distance_to_closest_line_ending > 60:\n",
    "                log('\\tToo far away!')\n",
    "                continue\n",
    "            if closest_line_ending in line_ending_to_closest_valley:\n",
    "                other, other_distance = line_ending_to_closest_valley[closest_line_ending]\n",
    "                log(f'\\tAlready used by {other} w/ dist {other_distance}')\n",
    "                if distance_to_closest_line_ending < other_distance:\n",
    "                    log(f'\\tIm closer! Throwing them out...')\n",
    "                    line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "                else:\n",
    "                    # TODO: inline annotations oppikken\n",
    "                    log(f'\\tThey are closer, carefully dying...')\n",
    "            else:\n",
    "                log(f'\\tFirst! Assigning...')\n",
    "                line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "        log(line_ending_to_closest_valley)\n",
    "\n",
    "        for line in lines:\n",
    "            line_ending = line[-1]\n",
    "            log(f'looking for line from line ending {line_ending}')\n",
    "            next_y = line_ending_to_closest_valley[line_ending][0] if line_ending in line_ending_to_closest_valley else line_ending\n",
    "            log(f'next: {next_y}')\n",
    "            line.append(next_y)\n",
    "    # End for chunk in chunks\n",
    "\n",
    "    # Get heights of every line\n",
    "    line_heights = []\n",
    "    for i, line_start in enumerate(line_starts):\n",
    "        if i==0:\n",
    "            line_heights.append(line_start)\n",
    "        else:\n",
    "            line_heights.append(line_start - line_starts[i-1])\n",
    "    line_heights.append(im.shape[0] - line_starts[-1])\n",
    "    line_heights = np.array(line_heights)\n",
    "\n",
    "    mean = line_heights.mean()\n",
    "    std = line_heights.std()\n",
    "    print(line_heights)\n",
    "    for i, line_height in enumerate(line_heights):\n",
    "        if line_height - mean > std:\n",
    "            print(f\"Second pass for line {i}\")\n",
    "            y_from = line_starts[i]\n",
    "            y_to = line_starts[i+1] if i < len(line_starts) else im.shape[0]\n",
    "            nested_lines, (nx, ny, nw, nh) = traverse(im[y_from:y_to, ...], n_splits, line_start_splits, start_lookahead, chunk_lookahead, second_pass=True, log=log)\n",
    "            nested_lines = []\n",
    "            for j, nested_line in enumerate(nested_lines):\n",
    "                lines.insert(i+j, nested_line)\n",
    "            # do something\n",
    "\n",
    "    lines_full = []\n",
    "    for line in lines:\n",
    "        line_full = []\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            line_full += [(y, w)]\n",
    "        lines_full.append(line_full)\n",
    "\n",
    "    return lines_full, dims\n",
    "    #\n",
    "    # im = annotate_image_with_lines(im, chunks, lines)\n",
    "    # pimg(im)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def test():\n",
    "    p = Path('../data/dss/scrolls')\n",
    "    files = p.glob('*binarized.jpg')\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        im = cv.imread(str(file))\n",
    "        im = preprocessed(im)\n",
    "        traverse(im)\n",
    "\n",
    "#test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test(axis=1):\n",
    "    im = cv.imread(IMG_PATH)\n",
    "    im = preprocessed(im)\n",
    "    ccs = get_ccs_from_image(im)\n",
    "    extreme_ccs = [cc for cc in ccs if cc.a < 500]\n",
    "    for cc in extreme_ccs:\n",
    "        im[cc.y:cc.y+cc.h, cc.x:cc.x+cc.w] = np.zeros((cc.h, cc.w))\n",
    "    im, d = crop(im)\n",
    "    pimg(im)\n",
    "    tiles = to_grid(im, 2, 2)\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    i=0\n",
    "    for (pos, tile) in tiles:\n",
    "        if cv.countNonZero(tile) < 5:\n",
    "            continue\n",
    "        reductions = reduce_optimally(tile, axis=axis)\n",
    "        tile, tile_dim = crop(tile)\n",
    "        tile = cv.cvtColor(tile, cv.COLOR_GRAY2RGB)\n",
    "        if reductions:\n",
    "            i+=1\n",
    "            path = f'/home/jsk/Study/2-4-hwr/Handwriting_Recognition/jesper_tests/out/{i}.jpg'\n",
    "            rotim = rot_from_red(tile, *reductions, axis=axis)\n",
    "            # print(f\"writing to {path}\")\n",
    "            cv.imwrite(path, rotim)\n",
    "            eqs = equations_from_reductions(tile, *reductions, axis=axis)\n",
    "            for x,y in eqs:\n",
    "                x_offset = pos.x + tile_dim[0]\n",
    "                y_offset = pos.y + tile_dim[1]\n",
    "                cv.line(tile, (y(0), x(0)), (y(tile.shape[1]), x(tile.shape[1])), (0, 255, 0), 1)\n",
    "                cv.line(im, (y(0)+x_offset, x(0)+y_offset), (y(tile.shape[1])+x_offset, x(tile.shape[1])+y_offset), (0, 255, 0), 1)\n",
    "            # print(r)\n",
    "            fig, (a1, a2) = plt.subplots(1, 2)\n",
    "            a1.imshow(rotim, cmap='binary')\n",
    "            a2.imshow(tile, cmap='binary')\n",
    "            plt.show()\n",
    "            # pimg(tile)\n",
    "    pimg(im)\n",
    "\n",
    "#test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def projection_profile(chunk, window_length=5):\n",
    "    reduced = cv.reduce(chunk // 255, 1, cv.REDUCE_SUM, dtype=cv.CV_32S).flatten()\n",
    "    kernel = np.ones(window_length) / window_length\n",
    "    return np.convolve(reduced, kernel, mode='same')\n",
    "\n",
    "\n",
    "def valleys_from_profile(profile, *args, **kwargs):\n",
    "    peaks, _ = peakdetect(profile, *args, **kwargs)\n",
    "    if len(peaks) == 0:\n",
    "        return []\n",
    "    peak_locs, _ = zip(*peaks)\n",
    "    # plt.plot(prof)\n",
    "    # for (x,y) in peaks:\n",
    "    #     plt.axvline(x)\n",
    "    # plt.show()\n",
    "    # start = cv.cvtColor(start, cv.COLOR_GRAY2RGB)\n",
    "    valley_locs = []\n",
    "    for i, y in enumerate(peak_locs):\n",
    "        if i==0:\n",
    "            continue\n",
    "        y_lag = peak_locs[i-1]\n",
    "        valley_locs.append(np.argmin(profile[y_lag:y]) + y_lag)\n",
    "        # valley = np.argmin(profile[y_lag:y]) + y_lag\n",
    "        # cv.line(start, (0, valley), (start.shape[1], valley), (0, 255, 0))\n",
    "    # plt.show()\n",
    "    # plt.imshow(start)\n",
    "    return valley_locs\n",
    "\n",
    "\n",
    "def annotate_image_with_lines(im, chunks, lines):\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    for line in lines:\n",
    "        x = im.shape[1]\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            cv.line(im, (x,y), (x-w,y), (0, 255, 0), 2)\n",
    "            if i < len(line)-1:\n",
    "                prev_y = line[i-1]\n",
    "                cv.line(im, (x,y), (x,prev_y), (0, 255, 0), 2)\n",
    "            x -= w\n",
    "    return im\n",
    "\n",
    "\n",
    "def none(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "def traverse(im, n_splits=20, line_start_splits=10, start_lookahead=70, chunk_lookahead=70, second_pass=False, log=none):\n",
    "    im, dims = crop(im)\n",
    "    if cv.countNonZero(im) == 0:\n",
    "        print('Empty image!')\n",
    "        return []\n",
    "    chunks = to_chunks(im, n_splits)\n",
    "\n",
    "    # Line starts\n",
    "    start = np.column_stack(tuple(chunks[-line_start_splits:]))\n",
    "    prof = projection_profile(start)\n",
    "    line_starts = valleys_from_profile(prof, lookahead=start_lookahead)\n",
    "    if len(line_starts) == 0:\n",
    "        print('Could not find any peaks!')\n",
    "        return []\n",
    "\n",
    "    lines = [[y] for y in line_starts]\n",
    "    valleys_per_chunk = [valleys_from_profile(projection_profile(chunk), lookahead=chunk_lookahead) \\\n",
    "                               for chunk in chunks]\n",
    "\n",
    "    # Line traversal\n",
    "    for i in range(2, n_splits+1):\n",
    "        log(f'\\nChunk {i}')\n",
    "        curr_valleys = valleys_per_chunk[-i]\n",
    "        log(f'Valleys at {curr_valleys}')\n",
    "        line_ending_to_closest_valley = {}\n",
    "        line_endings = [line[-1] for line in lines]\n",
    "        log(f'Line endings at {line_endings}')\n",
    "        for valley in curr_valleys:\n",
    "            log(f'Valley {valley}')\n",
    "            distances = np.array([abs(valley - line_ending) for line_ending in line_endings])\n",
    "            log(f'\\tDistances: {distances}')\n",
    "            closest_line_ending_idx = np.argmin(distances)\n",
    "            closest_line_ending = line_endings[closest_line_ending_idx]\n",
    "            distance_to_closest_line_ending = distances[closest_line_ending_idx]\n",
    "            log(f'\\tClosest at {closest_line_ending_idx}: {closest_line_ending} w/ distance {distance_to_closest_line_ending}')\n",
    "            if distance_to_closest_line_ending > 60:\n",
    "                log('\\tToo far away!')\n",
    "                continue\n",
    "            if closest_line_ending in line_ending_to_closest_valley:\n",
    "                other, other_distance = line_ending_to_closest_valley[closest_line_ending]\n",
    "                log(f'\\tAlready used by {other} w/ dist {other_distance}')\n",
    "                if distance_to_closest_line_ending < other_distance:\n",
    "                    log(f'\\tIm closer! Throwing them out...')\n",
    "                    line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "                else:\n",
    "                    # TODO: inline annotations oppikken\n",
    "                    log(f'\\tThey are closer, carefully dying...')\n",
    "            else:\n",
    "                log(f'\\tFirst! Assigning...')\n",
    "                line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "        log(line_ending_to_closest_valley)\n",
    "\n",
    "        for line in lines:\n",
    "            line_ending = line[-1]\n",
    "            log(f'looking for line from line ending {line_ending}')\n",
    "            next_y = line_ending_to_closest_valley[line_ending][0] if line_ending in line_ending_to_closest_valley else line_ending\n",
    "            log(f'next: {next_y}')\n",
    "            line.append(next_y)\n",
    "    # End for chunk in chunks\n",
    "\n",
    "    # Get heights of every line\n",
    "    line_heights = []\n",
    "    for i, line_start in enumerate(line_starts):\n",
    "        if i==0:\n",
    "            line_heights.append(line_start)\n",
    "        else:\n",
    "            line_heights.append(line_start - line_starts[i-1])\n",
    "    line_heights.append(im.shape[0] - line_starts[-1])\n",
    "    line_heights = np.array(line_heights)\n",
    "\n",
    "    mean = line_heights.mean()\n",
    "    std = line_heights.std()\n",
    "    print(line_heights)\n",
    "    for i, line_height in enumerate(line_heights):\n",
    "        if line_height - mean > std:\n",
    "            print(f\"Second pass for line {i}\")\n",
    "            y_from = line_starts[i]\n",
    "            y_to = line_starts[i+1] if i < len(line_starts) else im.shape[0]\n",
    "            nested_lines, (nx, ny, nw, nh) = traverse(im[y_from:y_to, ...], n_splits, line_start_splits, start_lookahead, chunk_lookahead, second_pass=True, log=log)\n",
    "            nested_lines = []\n",
    "            for j, nested_line in enumerate(nested_lines):\n",
    "                lines.insert(i+j, nested_line)\n",
    "            # do something\n",
    "\n",
    "    lines_full = []\n",
    "    for line in lines:\n",
    "        line_full = []\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            line_full += [(y, w)]\n",
    "        lines_full.append(line_full)\n",
    "\n",
    "    return lines_full, dims\n",
    "    #\n",
    "    # im = annotate_image_with_lines(im, chunks, lines)\n",
    "    # pimg(im)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def test():\n",
    "    p = Path('../data/dss/scrolls')\n",
    "    files = p.glob('*binarized.jpg')\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        im = cv.imread(str(file))\n",
    "        im = preprocessed(im)\n",
    "        traverse(im)\n",
    "\n",
    "#test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test(axis=1):\n",
    "    im = cv.imread(IMG_PATH)\n",
    "    im = preprocessed(im)\n",
    "    ccs = get_ccs_from_image(im)\n",
    "    extreme_ccs = [cc for cc in ccs if cc.a < 500]\n",
    "    for cc in extreme_ccs:\n",
    "        im[cc.y:cc.y+cc.h, cc.x:cc.x+cc.w] = np.zeros((cc.h, cc.w))\n",
    "    im, d = crop(im)\n",
    "    pimg(im)\n",
    "    tiles = to_grid(im, 2, 2)\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    i=0\n",
    "    for (pos, tile) in tiles:\n",
    "        if cv.countNonZero(tile) < 5:\n",
    "            continue\n",
    "        reductions = reduce_optimally(tile, axis=axis)\n",
    "        tile, tile_dim = crop(tile)\n",
    "        tile = cv.cvtColor(tile, cv.COLOR_GRAY2RGB)\n",
    "        if reductions:\n",
    "            i+=1\n",
    "            path = f'/home/jsk/Study/2-4-hwr/Handwriting_Recognition/jesper_tests/out/{i}.jpg'\n",
    "            rotim = rot_from_red(tile, *reductions, axis=axis)\n",
    "            # print(f\"writing to {path}\")\n",
    "            cv.imwrite(path, rotim)\n",
    "            eqs = equations_from_reductions(tile, *reductions, axis=axis)\n",
    "            for x,y in eqs:\n",
    "                x_offset = pos.x + tile_dim[0]\n",
    "                y_offset = pos.y + tile_dim[1]\n",
    "                cv.line(tile, (y(0), x(0)), (y(tile.shape[1]), x(tile.shape[1])), (0, 255, 0), 1)\n",
    "                cv.line(im, (y(0)+x_offset, x(0)+y_offset), (y(tile.shape[1])+x_offset, x(tile.shape[1])+y_offset), (0, 255, 0), 1)\n",
    "            # print(r)\n",
    "            fig, (a1, a2) = plt.subplots(1, 2)\n",
    "            a1.imshow(rotim, cmap='binary')\n",
    "            a2.imshow(tile, cmap='binary')\n",
    "            plt.show()\n",
    "            # pimg(tile)\n",
    "    pimg(im)\n",
    "\n",
    "#test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def projection_profile(chunk, window_length=5):\n",
    "    reduced = cv.reduce(chunk // 255, 1, cv.REDUCE_SUM, dtype=cv.CV_32S).flatten()\n",
    "    kernel = np.ones(window_length) / window_length\n",
    "    return np.convolve(reduced, kernel, mode='same')\n",
    "\n",
    "\n",
    "def valleys_from_profile(profile, *args, **kwargs):\n",
    "    peaks, _ = peakdetect(profile, *args, **kwargs)\n",
    "    if len(peaks) == 0:\n",
    "        return []\n",
    "    peak_locs, _ = zip(*peaks)\n",
    "    # plt.plot(prof)\n",
    "    # for (x,y) in peaks:\n",
    "    #     plt.axvline(x)\n",
    "    # plt.show()\n",
    "    # start = cv.cvtColor(start, cv.COLOR_GRAY2RGB)\n",
    "    valley_locs = []\n",
    "    for i, y in enumerate(peak_locs):\n",
    "        if i==0:\n",
    "            continue\n",
    "        y_lag = peak_locs[i-1]\n",
    "        valley_locs.append(np.argmin(profile[y_lag:y]) + y_lag)\n",
    "        # valley = np.argmin(profile[y_lag:y]) + y_lag\n",
    "        # cv.line(start, (0, valley), (start.shape[1], valley), (0, 255, 0))\n",
    "    # plt.show()\n",
    "    # plt.imshow(start)\n",
    "    return valley_locs\n",
    "\n",
    "\n",
    "def annotate_image_with_lines(im, chunks, lines):\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    for line in lines:\n",
    "        x = im.shape[1]\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            cv.line(im, (x,y), (x-w,y), (0, 255, 0), 2)\n",
    "            if i < len(line)-1:\n",
    "                prev_y = line[i-1]\n",
    "                cv.line(im, (x,y), (x,prev_y), (0, 255, 0), 2)\n",
    "            x -= w\n",
    "    return im\n",
    "\n",
    "\n",
    "def none(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "def traverse(im, n_splits=20, line_start_splits=10, start_lookahead=70, chunk_lookahead=70, second_pass=False, log=none):\n",
    "    im, dims = crop(im)\n",
    "    if cv.countNonZero(im) == 0:\n",
    "        print('Empty image!')\n",
    "        return []\n",
    "    chunks = to_chunks(im, n_splits)\n",
    "\n",
    "    # Line starts\n",
    "    start = np.column_stack(tuple(chunks[-line_start_splits:]))\n",
    "    prof = projection_profile(start)\n",
    "    line_starts = valleys_from_profile(prof, lookahead=start_lookahead)\n",
    "    if len(line_starts) == 0:\n",
    "        print('Could not find any peaks!')\n",
    "        return []\n",
    "\n",
    "    lines = [[y] for y in line_starts]\n",
    "    valleys_per_chunk = [valleys_from_profile(projection_profile(chunk), lookahead=chunk_lookahead) \\\n",
    "                               for chunk in chunks]\n",
    "\n",
    "    # Line traversal\n",
    "    for i in range(2, n_splits+1):\n",
    "        log(f'\\nChunk {i}')\n",
    "        curr_valleys = valleys_per_chunk[-i]\n",
    "        log(f'Valleys at {curr_valleys}')\n",
    "        line_ending_to_closest_valley = {}\n",
    "        line_endings = [line[-1] for line in lines]\n",
    "        log(f'Line endings at {line_endings}')\n",
    "        for valley in curr_valleys:\n",
    "            log(f'Valley {valley}')\n",
    "            distances = np.array([abs(valley - line_ending) for line_ending in line_endings])\n",
    "            log(f'\\tDistances: {distances}')\n",
    "            closest_line_ending_idx = np.argmin(distances)\n",
    "            closest_line_ending = line_endings[closest_line_ending_idx]\n",
    "            distance_to_closest_line_ending = distances[closest_line_ending_idx]\n",
    "            log(f'\\tClosest at {closest_line_ending_idx}: {closest_line_ending} w/ distance {distance_to_closest_line_ending}')\n",
    "            if distance_to_closest_line_ending > 60:\n",
    "                log('\\tToo far away!')\n",
    "                continue\n",
    "            if closest_line_ending in line_ending_to_closest_valley:\n",
    "                other, other_distance = line_ending_to_closest_valley[closest_line_ending]\n",
    "                log(f'\\tAlready used by {other} w/ dist {other_distance}')\n",
    "                if distance_to_closest_line_ending < other_distance:\n",
    "                    log(f'\\tIm closer! Throwing them out...')\n",
    "                    line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "                else:\n",
    "                    # TODO: inline annotations oppikken\n",
    "                    log(f'\\tThey are closer, carefully dying...')\n",
    "            else:\n",
    "                log(f'\\tFirst! Assigning...')\n",
    "                line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "        log(line_ending_to_closest_valley)\n",
    "\n",
    "        for line in lines:\n",
    "            line_ending = line[-1]\n",
    "            log(f'looking for line from line ending {line_ending}')\n",
    "            next_y = line_ending_to_closest_valley[line_ending][0] if line_ending in line_ending_to_closest_valley else line_ending\n",
    "            log(f'next: {next_y}')\n",
    "            line.append(next_y)\n",
    "    # End for chunk in chunks\n",
    "\n",
    "    # Get heights of every line\n",
    "    line_heights = []\n",
    "    for i, line_start in enumerate(line_starts):\n",
    "        if i==0:\n",
    "            line_heights.append(line_start)\n",
    "        else:\n",
    "            line_heights.append(line_start - line_starts[i-1])\n",
    "    line_heights.append(im.shape[0] - line_starts[-1])\n",
    "    line_heights = np.array(line_heights)\n",
    "\n",
    "    mean = line_heights.mean()\n",
    "    std = line_heights.std()\n",
    "    print(line_heights)\n",
    "    for i, line_height in enumerate(line_heights):\n",
    "        if line_height - mean > std:\n",
    "            print(f\"Second pass for line {i}\")\n",
    "            y_from = line_starts[i]\n",
    "            y_to = line_starts[i+1] if i < len(line_starts) else im.shape[0]\n",
    "            nested_lines, (nx, ny, nw, nh) = traverse(im[y_from:y_to, ...], n_splits, line_start_splits, start_lookahead, chunk_lookahead, second_pass=True, log=log)\n",
    "            nested_lines = []\n",
    "            for j, nested_line in enumerate(nested_lines):\n",
    "                lines.insert(i+j, nested_line)\n",
    "            # do something\n",
    "\n",
    "    lines_full = []\n",
    "    for line in lines:\n",
    "        line_full = []\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            line_full += [(y, w)]\n",
    "        lines_full.append(line_full)\n",
    "\n",
    "    return lines_full, dims\n",
    "    #\n",
    "    # im = annotate_image_with_lines(im, chunks, lines)\n",
    "    # pimg(im)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def test():\n",
    "    p = Path('../data/dss/scrolls')\n",
    "    files = p.glob('*binarized.jpg')\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        im = cv.imread(str(file))\n",
    "        im = preprocessed(im)\n",
    "        traverse(im)\n",
    "\n",
    "#test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "def test(axis=1):\n",
    "    im = cv.imread(IMG_PATH)\n",
    "    im = preprocessed(im)\n",
    "    ccs = get_ccs_from_image(im)\n",
    "    extreme_ccs = [cc for cc in ccs if cc.a < 500]\n",
    "    for cc in extreme_ccs:\n",
    "        im[cc.y:cc.y+cc.h, cc.x:cc.x+cc.w] = np.zeros((cc.h, cc.w))\n",
    "    im, d = crop(im)\n",
    "    pimg(im)\n",
    "    tiles = to_grid(im, 2, 2)\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    i=0\n",
    "    for (pos, tile) in tiles:\n",
    "        if cv.countNonZero(tile) < 5:\n",
    "            continue\n",
    "        reductions = reduce_optimally(tile, axis=axis)\n",
    "        tile, tile_dim = crop(tile)\n",
    "        tile = cv.cvtColor(tile, cv.COLOR_GRAY2RGB)\n",
    "        if reductions:\n",
    "            i+=1\n",
    "            path = f'/home/jsk/Study/2-4-hwr/Handwriting_Recognition/jesper_tests/out/{i}.jpg'\n",
    "            rotim = rot_from_red(tile, *reductions, axis=axis)\n",
    "            # print(f\"writing to {path}\")\n",
    "            cv.imwrite(path, rotim)\n",
    "            eqs = equations_from_reductions(tile, *reductions, axis=axis)\n",
    "            for x,y in eqs:\n",
    "                x_offset = pos.x + tile_dim[0]\n",
    "                y_offset = pos.y + tile_dim[1]\n",
    "                cv.line(tile, (y(0), x(0)), (y(tile.shape[1]), x(tile.shape[1])), (0, 255, 0), 1)\n",
    "                cv.line(im, (y(0)+x_offset, x(0)+y_offset), (y(tile.shape[1])+x_offset, x(tile.shape[1])+y_offset), (0, 255, 0), 1)\n",
    "            # print(r)\n",
    "            fig, (a1, a2) = plt.subplots(1, 2)\n",
    "            a1.imshow(rotim, cmap='binary')\n",
    "            a2.imshow(tile, cmap='binary')\n",
    "            plt.show()\n",
    "            # pimg(tile)\n",
    "    pimg(im)\n",
    "\n",
    "#test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "def projection_profile(chunk, window_length=5):\n",
    "    reduced = cv.reduce(chunk // 255, 1, cv.REDUCE_SUM, dtype=cv.CV_32S).flatten()\n",
    "    kernel = np.ones(window_length) / window_length\n",
    "    return np.convolve(reduced, kernel, mode='same')\n",
    "\n",
    "\n",
    "def valleys_from_profile(profile, *args, **kwargs):\n",
    "    peaks, _ = peakdetect(profile, *args, **kwargs)\n",
    "    if len(peaks) == 0:\n",
    "        return []\n",
    "    peak_locs, _ = zip(*peaks)\n",
    "    # plt.plot(prof)\n",
    "    # for (x,y) in peaks:\n",
    "    #     plt.axvline(x)\n",
    "    # plt.show()\n",
    "    # start = cv.cvtColor(start, cv.COLOR_GRAY2RGB)\n",
    "    valley_locs = []\n",
    "    for i, y in enumerate(peak_locs):\n",
    "        if i==0:\n",
    "            continue\n",
    "        y_lag = peak_locs[i-1]\n",
    "        valley_locs.append(np.argmin(profile[y_lag:y]) + y_lag)\n",
    "        # valley = np.argmin(profile[y_lag:y]) + y_lag\n",
    "        # cv.line(start, (0, valley), (start.shape[1], valley), (0, 255, 0))\n",
    "    # plt.show()\n",
    "    # plt.imshow(start)\n",
    "    return valley_locs\n",
    "\n",
    "\n",
    "def annotate_image_with_lines(im, chunks, lines):\n",
    "    im = cv.cvtColor(im, cv.COLOR_GRAY2RGB)\n",
    "    for line in lines:\n",
    "        x = im.shape[1]\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            cv.line(im, (x,y), (x-w,y), (0, 255, 0), 2)\n",
    "            if i < len(line)-1:\n",
    "                prev_y = line[i-1]\n",
    "                cv.line(im, (x,y), (x,prev_y), (0, 255, 0), 2)\n",
    "            x -= w\n",
    "    return im\n",
    "\n",
    "\n",
    "def none(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "def traverse(im, n_splits=20, line_start_splits=10, start_lookahead=70, chunk_lookahead=70, second_pass=False, log=none):\n",
    "    im, dims = crop(im)\n",
    "    if cv.countNonZero(im) == 0:\n",
    "        print('Empty image!')\n",
    "        return []\n",
    "    chunks = to_chunks(im, n_splits)\n",
    "\n",
    "    # Line starts\n",
    "    start = np.column_stack(tuple(chunks[-line_start_splits:]))\n",
    "    prof = projection_profile(start)\n",
    "    line_starts = valleys_from_profile(prof, lookahead=start_lookahead)\n",
    "    if len(line_starts) == 0:\n",
    "        print('Could not find any peaks!')\n",
    "        return []\n",
    "\n",
    "    lines = [[y] for y in line_starts]\n",
    "    valleys_per_chunk = [valleys_from_profile(projection_profile(chunk), lookahead=chunk_lookahead) \\\n",
    "                               for chunk in chunks]\n",
    "\n",
    "    # Line traversal\n",
    "    for i in range(2, n_splits+1):\n",
    "        log(f'\\nChunk {i}')\n",
    "        curr_valleys = valleys_per_chunk[-i]\n",
    "        log(f'Valleys at {curr_valleys}')\n",
    "        line_ending_to_closest_valley = {}\n",
    "        line_endings = [line[-1] for line in lines]\n",
    "        log(f'Line endings at {line_endings}')\n",
    "        for valley in curr_valleys:\n",
    "            log(f'Valley {valley}')\n",
    "            distances = np.array([abs(valley - line_ending) for line_ending in line_endings])\n",
    "            log(f'\\tDistances: {distances}')\n",
    "            closest_line_ending_idx = np.argmin(distances)\n",
    "            closest_line_ending = line_endings[closest_line_ending_idx]\n",
    "            distance_to_closest_line_ending = distances[closest_line_ending_idx]\n",
    "            log(f'\\tClosest at {closest_line_ending_idx}: {closest_line_ending} w/ distance {distance_to_closest_line_ending}')\n",
    "            if distance_to_closest_line_ending > 60:\n",
    "                log('\\tToo far away!')\n",
    "                continue\n",
    "            if closest_line_ending in line_ending_to_closest_valley:\n",
    "                other, other_distance = line_ending_to_closest_valley[closest_line_ending]\n",
    "                log(f'\\tAlready used by {other} w/ dist {other_distance}')\n",
    "                if distance_to_closest_line_ending < other_distance:\n",
    "                    log(f'\\tIm closer! Throwing them out...')\n",
    "                    line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "                else:\n",
    "                    # TODO: inline annotations oppikken\n",
    "                    log(f'\\tThey are closer, carefully dying...')\n",
    "            else:\n",
    "                log(f'\\tFirst! Assigning...')\n",
    "                line_ending_to_closest_valley[closest_line_ending] = (valley, distance_to_closest_line_ending)\n",
    "        log(line_ending_to_closest_valley)\n",
    "\n",
    "        for line in lines:\n",
    "            line_ending = line[-1]\n",
    "            log(f'looking for line from line ending {line_ending}')\n",
    "            next_y = line_ending_to_closest_valley[line_ending][0] if line_ending in line_ending_to_closest_valley else line_ending\n",
    "            log(f'next: {next_y}')\n",
    "            line.append(next_y)\n",
    "    # End for chunk in chunks\n",
    "\n",
    "    # Get heights of every line\n",
    "    line_heights = []\n",
    "    for i, line_start in enumerate(line_starts):\n",
    "        if i==0:\n",
    "            line_heights.append(line_start)\n",
    "        else:\n",
    "            line_heights.append(line_start - line_starts[i-1])\n",
    "    line_heights.append(im.shape[0] - line_starts[-1])\n",
    "    line_heights = np.array(line_heights)\n",
    "\n",
    "    mean = line_heights.mean()\n",
    "    std = line_heights.std()\n",
    "    print(line_heights)\n",
    "    for i, line_height in enumerate(line_heights):\n",
    "        if line_height - mean > std:\n",
    "            print(f\"Second pass for line {i}\")\n",
    "            y_from = line_starts[i]\n",
    "            y_to = line_starts[i+1] if i < len(line_starts) else im.shape[0]\n",
    "            nested_lines, (nx, ny, nw, nh) = traverse(im[y_from:y_to, ...], n_splits, line_start_splits, start_lookahead, chunk_lookahead, second_pass=True, log=log)\n",
    "            nested_lines = []\n",
    "            for j, nested_line in enumerate(nested_lines):\n",
    "                lines.insert(i+j, nested_line)\n",
    "            # do something\n",
    "\n",
    "    lines_full = []\n",
    "    for line in lines:\n",
    "        line_full = []\n",
    "        for i,y in enumerate(line):\n",
    "            curr_chunk = chunks[-(i+1)]\n",
    "            w = curr_chunk.shape[1]\n",
    "            line_full += [(y, w)]\n",
    "        lines_full.append(line_full)\n",
    "\n",
    "    return lines_full, dims\n",
    "    #\n",
    "    # im = annotate_image_with_lines(im, chunks, lines)\n",
    "    # pimg(im)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def test():\n",
    "    p = Path('../data/dss/scrolls')\n",
    "    files = p.glob('*binarized.jpg')\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        im = cv.imread(str(file))\n",
    "        im = preprocessed(im)\n",
    "        traverse(im)\n",
    "\n",
    "#test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}